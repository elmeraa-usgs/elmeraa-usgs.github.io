[
  {
    "objectID": "Research.html",
    "href": "Research.html",
    "title": "Research",
    "section": "",
    "text": "Winter 2022, Masters Group Project\n\n\nHigh runoff from urban areas has negative impacts on receiving water bodies. In Hawai’i, this problem is exacerbated by the natural landscape, which rapidly changes from steep ridges to low-lying valleys nearshore. Maunalua Bay, a region located on the southeastern coast of O’ahu, has been declared an impaired water body by the Hawai’i Department of Health due to high levels of nutrients and pollutants. Nine highly urbanized watersheds feed into Maunalua Bay, and runoff during storms deposits harmful sediment and pollutants into the Bay. To improve the health of Maunalua Bay, this project utilized hydrologic modeling to determine the runoff-reduction potential of green infrastructure under climate change projections. We created hydrologic models to determine areas of high runoff to guide where to prioritize green infrastructure placement within the urbanized environment. Green infrastructure is a useful means to capture runoff before it enters a waterbody. Targeting strategic locations for runoff reduction practices, such as green infrastructure, can reduce the quantity of runoff that feeds into Maunalua Bay, improving water quality. We also conducted a climate change analysis by modeling how future precipitation projections might influence regional runoff patterns. Our results can serve to inform stormwater management practices that prioritize green infrastructure placement in high runoff locations modeled under current and future climate scenarios."
  },
  {
    "objectID": "Research.html#identifying-fallowed-parcels-in-kern-county-california-using-an-ndvi-classification-from-landsat-8-toa-imagery",
    "href": "Research.html#identifying-fallowed-parcels-in-kern-county-california-using-an-ndvi-classification-from-landsat-8-toa-imagery",
    "title": "Research",
    "section": "Identifying Fallowed Parcels in Kern County, California using an NDVI Classification from Landsat-8 TOA Imagery",
    "text": "Identifying Fallowed Parcels in Kern County, California using an NDVI Classification from Landsat-8 TOA Imagery\nAgricultural abandonment (or fallowment) can be described as a situation where [the] human control over land (e.g. agriculture, forestry) is given up and the land is left to nature. Causes of agricultural abandonment range from social, economic, political and environmental factors. Environmental factors such as prolonged drought conditions and water use are drivers in abandoned lands. Persistent drought is creating water shortages throughout the Western United States, thus leading to an increase in the extent of unplanted agricultural lands in California’s Central Valley. Specifically, Kern County, located in California’s San Joaquin Valley, is the largest crop-producing county in California where farmers grow a wide variety of high-value commodities such as almonds, grapes, and pistachios. More recently, Kern County farmers have been faced with persistent drought conditions leading to water shortages and ultimately fallowed lands. Drought conditions across the state have been exacerbated by high temperatures, with 2012–2014 being the hottest three-year period on record. Here, we focus our analysis identifying fallowed parcels in Kern County, California during the 2015 drought period utilizing Top of Atmosphere (TOA) Landsat-8 Imagery from Google Earth Engine (GEE) API."
  },
  {
    "objectID": "Research.html#rainfall-gradients-across-the-isthmus-of-panama",
    "href": "Research.html#rainfall-gradients-across-the-isthmus-of-panama",
    "title": "Research",
    "section": "Rainfall gradients across the Isthmus of Panama",
    "text": "Rainfall gradients across the Isthmus of Panama\nAs climate changes, tropical forests will be affected by changes in precipitation and temperature, resulting in feedbacks to global climate and processes. The Functionally-Assembled Terrestrial Ecosystem Simulator (FATES) model, being developed at Berkeley Lab, is structured and parameterized to represent ecological dynamics of tropical forests under different environmental regimes. In this analysis, we assimilated and characterized climate data measured from three sites (Parque Nacional Metropolitano (PNM), Barro Colorado Island (BCI), and Parque Nacional San Lorenzo (SLZ) along a rainfall gradient in Panama. We examined the effects of the rainfall gradient on the FATES predictions of GPP. We found as precipitation increased GPP increased between the three sites, and we found no differences in wet season GPP per leaf area across sites, indicating solar radiation (SR) is driving differences in GPP across the rainfall gradients sites. We also found canopy biomass was highest at SLZ, BCI then PNM during the wet season. However, understory biomass had a declining effect across all sites in the wet season. This work assists in the development and evaluation of the FATES model and aid in predicting the impacts of climate change on forest ecosystem processes and functions."
  },
  {
    "objectID": "Research.html#global-photosynthetic-capacity-vcmax-within-canopies",
    "href": "Research.html#global-photosynthetic-capacity-vcmax-within-canopies",
    "title": "Research",
    "section": "Global Photosynthetic Capacity (Vcmax) within Canopies",
    "text": "Global Photosynthetic Capacity (Vcmax) within Canopies\nMaximum rubisco carboxylation rate (Vcmax) varies with daily integrated quantum flux density (Qint) along vertical transects within forest canopies. In this study, we investigated what drives the patterns of Vcmax plasticity observed within forest canopies, where gradient in light availability from canopy top to bottom can be >50-fold. We conducted correlation analyses of Vcmax plasticity against both environmental (light: PAR, temperature, vapor pressure deficit: VPD, elevation, latitude & longitude) and soil (soil water availability: a, silt content, clay content, pH, C:N & cation exchange capacity: CECS, water content: WC) parameters to explore their influence on Vcmax plasticity within forest canopies and different vegetation types (Deciduous broadleaved forests: Decid. BL, Evergreen temperate: Evergr. temp, Evergreen needle leaf: Evergr. NL, & Evergreen tropical: Evergr. trop). We calculated Vcmax plasticity between Qint step changes: 1-3, 3-6, 6-12,12-20, 20-30, 30-40. For environmental and soil parameters, the most commonly correlated Vcmax plasticity step changes included: plasticity changes 30-40 and 6-12. Our results revealed that Vcmax plasticity varied within plant functional types (PFTs) and for environmental and soil parameters. Two out of seven environmental parameters -VPD and PAR-, and three out of six soil parameters -a, WC & C:N- showed strong correlations across PFTs for Vcmax plasticity step change 12-20. Evergr. NL forests showed strong correlation between Vcmax plasticity step change 12-20 and VPD (R = 0.61); PAR was also strongly correlated with this plasticity step change (R = 0.56); a was negatively correlated within Evergr. NL (R = -0.77); WC was negatively correlated within Decid. BL (R = -0.33); C:N was negatively correlated within Evergr. trop (R = -0.31). PFTs also showed strong correlations between plasticity step change 30-40 for individual environmental and soil parameters. For example, within Decid. BL Vcmax plasticity step change 30-40, results showed elevation (R = 0.92), VPD (R = 0.79) and PAR (R = 0.82) were the strongly correlated. Our study offers an analysis of the relative influence of environmental vs soil parameters on within canopy Vcmax plasticity that can help to better represent global photosynthetic capacity in Earth system models (ESMs).\n\n\n\nSummer 2019, Fertilization Study in SLC"
  },
  {
    "objectID": "Research.html#inorganic-vs.-organic-fertilizer",
    "href": "Research.html#inorganic-vs.-organic-fertilizer",
    "title": "Research",
    "section": "Inorganic vs. organic fertilizer",
    "text": "Inorganic vs. organic fertilizer\n While lawn management practices have altered the capacity for urban lawns to act as Nitrogen (N) sinks, there have been few studies of the effects of organic vs. inorganic fertilizer additions to urban lawns. We evaluated how foliar and soil N content and isotopic N composition (δ15N) varied as a result of different fertilizer treatment (inorganic, organic or control). We also evaluated differences in lawn above ground net primary productivity (ANPP) among fertilization treatments. We hypothesized that (1) lawn plots managed with organic fertilizer would exhibit lower leaf %N than inorganic fertilizer treatments due to N cycling and losses via leaching; (2) organic fertilizer would exhibit more enriched δ15N in plant and soil tissue due to trophic level effects of animal derived N; (3) the fertilization effect on %N of grasses and soil would be strongest immediately following fertilization and taper off throughout the growing season due to N mineralization losses and immobilization; (4) if soils are N-limited prior to fertilization, fertilized plots - regardless of form (inorganic or organic) – would have higher ANPP compared with control plots. We found that lawn plots managed with organic fertilizer had lower leaf %N than inorganic fertilizer plots, and that all fertilized plots showed a declining treatment effect on %N over time. However, treatment effects on δ15N varied over time. We found that organic fertilizer plots had significantly lower foliar δ15N than inorganic and control throughout the growing season. Finally, we found no differences in ANPP across treatments for plots. In this study, fertilizer treatments did not stimulate ANPP of grasses, suggesting that these lawns were not strongly N-limited prior to fertilization."
  },
  {
    "objectID": "posts/2021-02-23-text-wrangling-and-analysis/text-wrangling-and-analysis.html",
    "href": "posts/2021-02-23-text-wrangling-and-analysis/text-wrangling-and-analysis.html",
    "title": "Text wrangling and analysis",
    "section": "",
    "text": "Load packages\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(tidytext)\nlibrary(textdata)\nlibrary(pdftools)\nlibrary(ggwordcloud)\n\n\n\nRead in the Origin of Species, 6th Edition by Darwin\n\nos_text <- pdf_text(here(\"posts\", \"2021-02-23-text-wrangling-and-analysis\", \"originofspecies6th-darwin.pdf\"))\n\n\n\nText into a data frame, then wrangling with the tidyverse, break it up by chapter, and do some basic analyses.\n\nos_tidy <- data.frame(os_text) %>% \n  mutate(text_full = str_split(os_text, pattern = '\\\\n')) %>% \n  unnest(text_full) %>% \n  mutate(text_full = str_trim(text_full))\n\n\nos_df <- os_tidy %>% \n  slice(-(1:184)) %>% \nmutate(chapter = case_when(\n     str_detect(text_full, \"CHAPTER\") ~ str_extract(text_full, \"CHAPTER [1-9]+\"),\n     TRUE ~ NA_character_\n   )) %>% \n  fill(chapter) %>% \n  separate(col = chapter, into = c(\"cha\", \"no\"), sep = \" \") %>% \n  mutate(chapter = as.numeric(no))\n\n\n\nWord count by Chapter\n\nos_tokens <- os_df %>% \n  unnest_tokens(word, text_full) %>% \n  select(-os_text) \n\nos_tokens_clean <- os_tokens %>%\n   mutate(word = str_replace(word, \"[0-9-]+\", NA_character_)) %>% \n  drop_na()\n\nos_wordcount <- os_tokens_clean %>% \n  count(chapter, word) \n\n\n\nRemove stop words and recounting again\n\nos_nonstop_words <- os_tokens_clean %>% \n  anti_join(stop_words)\n\nJoining, by = \"word\"\n\nnonstop_counts <- os_nonstop_words %>% \n  count(chapter, word) \n\n\n\nTop 5 words by chapter\n\ntop_5_words <- nonstop_counts %>% \n  group_by(chapter) %>% \n  arrange(-n) %>% \n  slice(1:5)\n\nch_names <- list(\n  \"1\" =\"Chapter 1\",\n  \"2\" = \"Chapter 2\",\n  \"3\" = \"Chapter 3\",\n  \"4\" = \"Chapter 4\",\n  \"5\" = \"Chapter 5\",\n  \"6\" = \"Chapter 6\",\n  \"7\" = \"Chapter 7\",\n  \"8\" = \"Chapter 8\",\n  \"9\" = \"Chapter 9\",\n  \"10\" = \"Chapter 10\",\n  \"11\" = \"Chapter 11\",\n  \"12\" = \"Chapter 12\",\n  \"13\" = \"Chapter 13\",\n  \"14\" = \"Chapter 14\",\n  \"15\" = \"Chapter 15\"\n )\n\nch_labeller <- function(variable,value){\n  return(ch_names[value])\n}\n\n## vizualization\nggplot( data = top_5_words,\n        aes(reorder(word, n), n )) +\n  geom_col(fill = \"forestgreen\") +\n  facet_wrap(~chapter, scales = \"free\", labeller=ch_labeller) +\n  coord_flip() +\n  theme_minimal() +\n  labs(x = \"Word\", y = \" Count\")\n\n\n\n\n\n\nWord cloud for all text\n\nnonstop_counts_full <- os_nonstop_words %>% \n  count(word) \n\nos_top100_removesps <- nonstop_counts_full %>% \n  arrange(-n) %>% \n  slice(1:100)\n\nos_cloud <- ggplot(data = os_top100_removesps, aes(label = word)) +\n  geom_text_wordcloud(aes(color = n, size = n), shape = \"circle\") +\n  scale_size_area(max_size = 10) +\n  scale_color_gradient(low = \"darkseagreen\", high = \"forestgreen\") +\n  theme_minimal()\n\nos_cloud\n\n\n\n#ggsave(here(\"src\",\"originofspecies-wc-ea.png\"), width = 8, height = 5) # to save\n\n\n\nSentiment analysis using “NRC” lexicon\n\n## nrc to just check out\nos_nrc <- os_nonstop_words %>% \n  inner_join(get_sentiments(\"nrc\"))\n\nJoining, by = \"word\"\n\nos_nrc_counts <- os_nrc %>% \n  count(chapter, sentiment)\n\nos_nrc_viz<- ggplot(data = os_nrc_counts, aes(x = sentiment, y = n)) +\n  geom_col() +\n  facet_wrap(~chapter, labeller=ch_labeller) + # ch_labeller function defined in steps above \n  coord_flip() +\n  theme_minimal(base_size = 14) +\n  theme(axis.title.y = element_text(margin = margin(t = 20, r = 0, b = 0, l = 20))) + \n  labs(y = \"Word Count\", x = \"NRC sentiment\", title = \"Sentiment analysis of the Origin of Species by Charles Darwin \\nusing NRC from Saif Mohammad and Peter Turney\") \n\nggsave(\"origin-of-species-nrc-analysis.png\", os_nrc_viz, width = 12, height = 8, units = \"in\", dpi = 300)\n\n\n\n\nCitations:\n\nNRC lexicon: Crowdsourcing a Word-Emotion Association Lexicon, Saif Mohammad and Peter Turney, Computational Intelligence, 29 (3), 436-465, 2013.\nOrigin of Species Text"
  },
  {
    "objectID": "posts/2021-02-23-chisquare-politcal/chisquare-politcal.html",
    "href": "posts/2021-02-23-chisquare-politcal/chisquare-politcal.html",
    "title": "Survey responses of political affiliation and recognition as an environmentalist with chi-square analysis",
    "section": "",
    "text": "library(tidyverse)\nlibrary(here)\nlibrary(janitor)\nlibrary(broom)\nlibrary(kableExtra)\n\n\n\n\nthe survey data can be found in the data folder of this repo; the Rmd and html files, denoted as a6-task2, can be found in the src folder\nthe qmd format can be found here"
  },
  {
    "objectID": "posts/2021-02-23-chisquare-politcal/chisquare-politcal.html#introduction",
    "href": "posts/2021-02-23-chisquare-politcal/chisquare-politcal.html#introduction",
    "title": "Survey responses of political affiliation and recognition as an environmentalist with chi-square analysis",
    "section": "Introduction:",
    "text": "Introduction:\nThis task analyzes the association between respondents’ political affiliation (coined “conservative” or “liberal” by self-identification) and if they consider themself an environmentalist. The variables in the dataset (conservation_survey.csv) I have used include:\n\nenv_id: response to survey statement “I consider myself an environmentalist,” with outcomes 1 = Yes, 2 = No, 3 = Unsure\npol_or: response to survey question “How do you self-identify politically?” Response values 1 - 3 are “conservative” (strongly to slightly), and values 5 - 7 are “liberal” (slightly to strongly).\n\n\n## Read in survey data \nsurvey <- read_csv(here(\"posts\", \"2021-02-23-chisquare-politcal\", \"conservation_survey.csv\"))\n\nRows: 1331 Columns: 95\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): DBCODE\ndbl (94): ENTITY, QUALTRICSID, TIME, GEND, AGE, AGE_RANGE, INCO, EDU, RACE, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n## only keep variables: 'env_id' and 'pol_or'\nsurvey_clean <- survey %>% \n  clean_names() %>% \n  dplyr::select(env_id, pol_or) %>% \n  mutate(party = case_when(\n    between(pol_or, 1,3) ~ \"conservative\",\n    between(pol_or, 5,7) ~ \"liberal\",\n    TRUE ~ NA_character_))\n\nsurvey_environmentalist <- survey_clean %>%  \n  mutate(environmentalist = case_when(\n   env_id == 1 ~ \"yes\",\n   env_id == 2 ~ \"no\",\n   env_id == 3 ~ \"unsure\"))\n\n\n## Finalized table that shows counts and proportions of \"liberal\" and \"conservative\" survey respondents who responded with \"yes\", \"no\" and \"unsure\" to the statement: \"I consider myself an environmentalist\"\nsurvey_counts <- survey_environmentalist %>% \n  janitor::tabyl(party, environmentalist)\n\nsurvey_proportions <- survey_counts %>% \n  adorn_percentages() %>% \n  janitor::adorn_pct_formatting(digits = 2) %>% \n  adorn_ns() %>% \n  drop_na()\n\nsurvey_ct <- survey_proportions %>% \n  column_to_rownames(var = \"party\")\n\nsurvey_ct %>%  \n  kable(col.names = c(\"No\",\n                      \"Unsure\",\n                      \"Yes\"),\n    caption = \"**Table 1**: Association between respondents’ political affiliation (“conservative” or “liberal” by self-identification) vs if they consider themself an environmentalist\") %>% \n  kable_styling(full_width = FALSE) \n\n\n\n**Table 1**: Association between respondents’ political affiliation (“conservative” or “liberal” by self-identification) vs if they consider themself an environmentalist\n \n  \n      \n    No \n    Unsure \n    Yes \n  \n \n\n  \n    conservative \n    50.24% (318) \n    16.11% (102) \n    33.65% (213) \n  \n  \n    liberal \n    24.47% (128) \n    21.80% (114) \n    53.73% (281) \n  \n\n\n\n\n\n\n## Chi-square test\nsurvey_ct <- survey_counts %>%   \n  drop_na() %>% \n  column_to_rownames(var = \"party\")\n  \nsurvey_x2 <- chisq.test(survey_ct)\nsurvey_x2\n\n\n    Pearson's Chi-squared test\n\ndata:  survey_ct\nX-squared = 81.237, df = 2, p-value < 2.2e-16\n\nsurvey_tidy <- tidy(survey_x2)"
  },
  {
    "objectID": "posts/2021-02-23-chisquare-politcal/chisquare-politcal.html#chi-square-results-and-summary",
    "href": "posts/2021-02-23-chisquare-politcal/chisquare-politcal.html#chi-square-results-and-summary",
    "title": "Survey responses of political affiliation and recognition as an environmentalist with chi-square analysis",
    "section": "Chi-square results and summary",
    "text": "Chi-square results and summary\nA chi-square test for independence compares two variables in a contingency table to see if they are related. In a more general sense, it tests to see whether distributions of categorical variables differ from each another. For this analysis, there is a significant association (i.e. non-independence) between political affiliation and and if a person considers themself an environmentalist ($\\chi$2(2) = 81.24, p-value = 2.29e-18).\n\nCitations:\n\nAndrews Forest LTER Site and C. Batavia. 2019. Influences on charitable giving for conservation: Online survey data of 1,331 respondents across the US, August 2017 ver 3. Environmental Data Initiative. https://doi.org/10.6073/pasta/926e6270e324a1322a900da14d38b96c\nMetadata, including survey questions and possible responses, are here: https://portal.edirepository.org/nis/metadataviewer?packageid=knb-lter-and.5444.3"
  },
  {
    "objectID": "posts/2022-08-26-spotifyr-exploration/2022-08-26-spotifyr-exploration.html",
    "href": "posts/2022-08-26-spotifyr-exploration/2022-08-26-spotifyr-exploration.html",
    "title": "spotifyr exploration",
    "section": "",
    "text": "Load packages\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(spotifyr)\nlibrary(purrr)\nlibrary(knitr)\nlibrary(ggridges)\nlibrary(ggjoy)\nlibrary(plotly) \nlibrary(jsonlite)\nlibrary(lubridate)\nlibrary(gghighlight)\n\n\n\nFind My All Time Favorite Artists\n\n## Set up \n# Sys.setenv(SPOTIFY_CLIENT_ID = 'xxxxxxxxxxxxxxxxxxxxx')\n# Sys.setenv(SPOTIFY_CLIENT_SECRET = 'xxxxxxxxxxxxxxxxxxxxx')\n# access_token <- get_spotify_access_token()\n\ntop_art_tracks_long <- get_my_top_artists_or_tracks(type = 'artists', \n                             time_range = 'long_term', \n                             limit = 50) %>% \n    select(.data$name, .data$genres) %>% \n    rowwise %>% \n    mutate(genres = paste(.data$genres, collapse = ', ')) %>% \n    ungroup \n\ntop_art_tracks_long %>%\n  head(10) %>% \n  kable()\n\n\n\n\n\n\n\n\nname\ngenres\n\n\n\n\nTaylor Swift\npop\n\n\nDrake\ncanadian hip hop, canadian pop, hip hop, rap, toronto rap\n\n\nKehlani\npop, r&b, rap\n\n\nThe Weeknd\ncanadian contemporary r&b, canadian pop, pop\n\n\nHarry Styles\npop\n\n\nAriana Grande\ndance pop, pop\n\n\nJustin Bieber\ncanadian pop, pop\n\n\nAminé\nhip hop, pop, portland hip hop, rap\n\n\nMUNA\ndance pop, electropop, indie pop, indie poptimism, la pop, metropopolis, pop\n\n\nPost Malone\ndfw rap, melodic rap, rap\n\n\n\n\n\n\n\nWhat are the most joyful Harry Styles songs and albums ?\n\nharry_styles <- get_artist_audio_features('harry styles')\n\nharry_styles_joyful_songs <- harry_styles %>% \n    arrange(-valence) %>% \n    select(.data$track_name, .data$valence, .data$album_name) %>% \n  head(20) \n\nggplot(\n    harry_styles_joyful_songs, \n    aes(y = valence, x = reorder(track_name, valence))\n    ) + \ngeom_col(aes(color = album_name, fill = album_name, width=.5)) +\nscale_color_manual(values=c(\"#25b6d5\", \"#b1bf46\", \"#813f2b\"), name = \"Album Name\") +\nscale_fill_manual(values=c(\"#25b6d5\", \"#b1bf46\", \"#813f2b\"), name = \"Album Name\") + \n  coord_flip() + \nlabs(title = \"Harry Styles track distribution on musical positiveness\", \n     subtitle = \"Based on valence pulled from Spotify's Web API with spotifyr\",\n     y = \"Valence\",\n     x = \"Track Name\") +\n  geom_text(aes(label = round(valence, digits = 3)), position=position_dodge(width=1.0), hjust= -0.30, size=3) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0,1))  +\n  theme_minimal(base_size = 12) +\n  theme(axis.text.x=element_blank(),\n        axis.ticks.x = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        legend.position = \"top\")\n\n\n\nggplot(harry_styles, \n    aes(x = energy, y = album_name, fill = ..x..)) + \ngeom_density_ridges_gradient(show.legend = FALSE) + \n   scale_fill_viridis_c(option = \"C\") + \n  labs(x = \"Energy\",\n       y = \"Album Name\") +\n  theme_minimal(base_size = 16) +\n  theme(panel.grid.major.y = element_blank())\n\n\n\n\n\n\nExploring Harry Style’s discography on danceabiliy vs. valence (music positiveness)\n\nvalence : A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n\n\nhs <- harry_styles %>% \n  rename(album = album_name, \n         track = track_name) %>% \n  ggplot(aes(x = valence, y = danceability)) + \ngeom_point(size = 2, aes(color = album, group = track)) +\n  scale_color_manual(values=c(\"#25b6d5\", \"#b1bf46\", \"#813f2b\"), name = \"Album Name\") +\n  theme_minimal() +\n  labs(x = \"Valence\",\n        y =  \"Danceability\") +\n  theme(legend.position=\"bottom\") +\n  scale_x_continuous(expand = c(0, 0), limits = c(0,1)) + \n  scale_y_continuous(expand = c(0, 0), limits = c(0, 1))\n\nggplotly(hs) %>% \nlayout(legend = list(orientation = \"h\",   # show entries horizontally\n                     xanchor = \"center\",  # use center of legend as anchor\n                     x = 0.5, # put legend in center of x-axis\n                     y = -0.15))  # adjust legend text so its not overlapping with x-axis        \n\n\n\n\n\n\n\n\nExplore my downloaded spotify history\n\nI downloaded my data at https://www.spotify.com/us/account/privacy/. After logging in, you can select “Download your data” and follow the steps to retrieve your data from your email.\n\n\n\n# Reading JSON and streaming history\nstreamHistory0 <- fromJSON(\"StreamingHistory0.json\", flatten = TRUE)\nstreamHistory1 <- fromJSON(\"StreamingHistory1.json\", flatten = TRUE)\nstreamHistory2 <- fromJSON(\"StreamingHistory2.json\", flatten = TRUE)\nstreamHistory3 <- fromJSON(\"StreamingHistory3.json\", flatten = TRUE)\n\n# Combine all histories \nstreamHistAll = rbind(streamHistory0, streamHistory1, streamHistory2, streamHistory3)\n\n\n# Adding date and timing \nmySpotify <- streamHistAll %>% \n  as_tibble() %>% \n  mutate_at(\"endTime\", ymd_hm) %>% \n  mutate(endTime = endTime - hours(6)) %>% \n  mutate(date = floor_date(endTime, \"day\") %>% as_date, seconds = msPlayed / 1000, minutes = seconds / 60)\n\n# Playback activity per week and hours\nstreamingHours <- mySpotify %>% \n  filter(date >= \"2020-01-01\") %>% \n  group_by(date) %>% \n  group_by(date = floor_date(date, \"week\")) %>%\n  summarize(hours = sum(minutes) / 60) %>% \n  arrange(date) %>% \n  ggplot(aes(x = date, y = hours)) + \n  geom_col(aes(fill = hours)) +\n  scale_fill_gradient(low = \"yellow\", high = \"red\") + \n  labs(x= \"Date\", y= \"Hours of music playback\", fill = \"Hours\") + \n  ggtitle(\"On what dates I've listened to more or less music on Spotify?\", \"Playback activity per week\")+\n  theme_minimal() +\n  theme(legend.position=\"bottom\")\n\nstreamingHours\n\n\n\n\n\n\nOn what dates did you listen to more or less music by a specific artist?\n\n# Playback activity for Harry Styles & Taylor Swift\nhoursArtist <- mySpotify %>% \n  group_by(artistName, date = floor_date(date, \"month\")) %>% \n  summarize(hours = sum(minutes) / 60) %>% \n  ggplot(aes(x = date, y = hours, group = artistName)) + \n  labs(x= \"Date\", y= \"Hours of music playback\") + \n  ggtitle(\"On what dates I've listened to more or less music by a specific artist?\", \"E.g: Harry Styles and Taylor Swift\") +\n  geom_line(aes(color = artistName)) + \n  gghighlight(artistName == \"Harry Styles\" || artistName == \"Taylor Swift\") +\n  theme_minimal()\n\nhoursArtist\n\n\n\n\n\n\nWhat were the artists you listened to the most on your Spotify?\n\n# Most listened artist (more than 3 hours)\nminutesMostListened <- mySpotify %>% \n  filter(date >= \"2020-01-01\") %>% \n  group_by(artistName) %>% \n  summarize(minutesListened = sum(minutes)) %>% \n  filter(minutesListened >= 180) %>%\n  ggplot(aes(x = reorder(artistName, -minutesListened), y = minutesListened)) + \n  geom_col(aes(fill = minutesListened)) +\n  scale_fill_gradient(low = \"yellow\", high = \"red\") + \n  labs(x= \"Artist\", y= \"Minutes of music playback\", fill = \"Minutes Listened\") + \n  theme_minimal(base_size = 18) +\n  ggtitle(\"What were the most listened artists on my Spotify?\", \"> 3 hours listened\") +\n  theme(axis.text.x = element_text(angle = 90), \n        legend.position = \"none\") \n\nminutesMostListened\n\n\n\n\n\n\nExploring my liked tracks\n\n# Get favorite tracks from likes\nmyFavTracks <- ceiling(get_my_saved_tracks(include_meta_info = TRUE)[['total']] / 50) %>%\n  seq() %>%\n  map(function(x) {\n    get_my_saved_tracks(limit = 50, offset = (x - 1) * 50)\n  }) %>% \n  reduce(rbind) %>%\n  write_rds('raw_myFavTracks.rds')\n\n\n\nWhat my top artists based on my liked tracks?\n\nfavTracksArtist <- myFavTracks %>%\n  select(track.artists) %>%\n  reduce(rbind) %>%\n  reduce(rbind) %>%\n  select(id, name)\ntrackNumArtist <- favTracksArtist %>%\n  count(id, sort = TRUE) %>%\n  left_join(favTracksArtist, by = 'id',.) %>%\n  unique() %>%\n  select(-id) %>%\n  top_n(10, n)\n\n# Plot top 10 artists based on liked tracks \nplotMyFavs <- trackNumArtist %>%\n  mutate(freq = case_when(n > 100 ~ '> 100 tracks',\n      between(n, 50, 99) ~ '50-99 tracks',\n      between(n, 20, 49) ~ '20-49 tracks',\n      TRUE ~ '< 20 tracks')) %>%\n  mutate(freq = factor(freq, levels = c('> 100 tracks', '50-99 tracks', '20-49 tracks', '< 20 tracks'))) %>%\n  ggplot(mapping = aes(x = reorder(name, -n), y = n, fill = freq)) +\n  geom_col() +\n  scale_fill_brewer(palette=\"Dark2\") +\n  labs(x= \"Artist name\", y= \"Number of tracks\", fill = NULL) +\n  ggtitle(\"What are my Top 10 favorite artists?\", \"Based on my ♥ tracks\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90), \n        legend.position=\"bottom\")\n\nplotMyFavs"
  },
  {
    "objectID": "posts/2021-09-18-black-throated-blue-warblers-visualization/black-throated-blue-warblers-visualization.html",
    "href": "posts/2021-09-18-black-throated-blue-warblers-visualization/black-throated-blue-warblers-visualization.html",
    "title": "Black-Throated Blue Warblers linear model selection",
    "section": "",
    "text": "the warblers data can be found in the exam_data folder of this repo; the Rmd and html files can be found in the task_code folder\nthe qmd format can be found here\n\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(broom)\nlibrary(car)\nlibrary(GGally)\nlibrary(stargazer)\n\n\n## Read in bt_warblers.csv\nwarblers <- read_csv(here(\"posts\", \"2021-09-18-black-throated-blue-warblers-visualization\",\"bt_warblers.csv\"))"
  },
  {
    "objectID": "posts/2021-09-18-black-throated-blue-warblers-visualization/black-throated-blue-warblers-visualization.html#data-exploration-and-visualization",
    "href": "posts/2021-09-18-black-throated-blue-warblers-visualization/black-throated-blue-warblers-visualization.html#data-exploration-and-visualization",
    "title": "Black-Throated Blue Warblers linear model selection",
    "section": "Data exploration and visualization",
    "text": "Data exploration and visualization\n\n\n\n\n\n\n\n\n\n\n\n\n## Model 1: DV is bird mass, predictor variables are: right wing length (mm), tarsus length (mm), age of bird at capture, and sex. \nwarblers_lm <- lm(mass ~ wing_r + tarsus1 + age_banded + sex, data = warblers_clean)\nsummary(warblers_lm)\n\n\nCall:\nlm(formula = mass ~ wing_r + tarsus1 + age_banded + sex, data = warblers_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.8621 -0.3485 -0.0150  0.3692  4.9237 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    4.613330   1.118242   4.126 4.17e-05 ***\nwing_r         0.073854   0.015641   4.722 2.86e-06 ***\ntarsus1        0.074342   0.033644   2.210   0.0275 *  \nage_bandedASY -0.005195   0.138458  -0.038   0.9701    \nage_bandedSY   0.016213   0.135266   0.120   0.9046    \nsexM          -1.042929   0.072653 -14.355  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5926 on 661 degrees of freedom\nMultiple R-squared:  0.3208,    Adjusted R-squared:  0.3157 \nF-statistic: 62.44 on 5 and 661 DF,  p-value: < 2.2e-16\n\nAIC(warblers_lm) # 1202.795\n\n[1] 1202.795\n\nvif(warblers_lm) \n\n               GVIF Df GVIF^(1/(2*Df))\nwing_r     2.344573  1        1.531200\ntarsus1    1.041942  1        1.020755\nage_banded 1.141061  2        1.033540\nsex        2.505606  1        1.582911\n\nwarblers_lm \n\n\nCall:\nlm(formula = mass ~ wing_r + tarsus1 + age_banded + sex, data = warblers_clean)\n\nCoefficients:\n  (Intercept)         wing_r        tarsus1  age_bandedASY   age_bandedSY  \n     4.613330       0.073854       0.074342      -0.005195       0.016213  \n         sexM  \n    -1.042929  \n\nwarblers_lm_tidy <- tidy(warblers_lm)\nwarblers_lm_tidy\n\n# A tibble: 6 × 5\n  term          estimate std.error statistic  p.value\n  <chr>            <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)    4.61       1.12      4.13   4.17e- 5\n2 wing_r         0.0739     0.0156    4.72   2.86e- 6\n3 tarsus1        0.0743     0.0336    2.21   2.75e- 2\n4 age_bandedASY -0.00520    0.138    -0.0375 9.70e- 1\n5 age_bandedSY   0.0162     0.135     0.120  9.05e- 1\n6 sexM          -1.04       0.0727  -14.4    7.12e-41\n\nwarblers_lm_fit <- glance(warblers_lm)\nwarblers_lm_fit\n\n# A tibble: 1 × 12\n  r.squared adj.r.squa…¹ sigma stati…²  p.value    df logLik   AIC   BIC devia…³\n      <dbl>        <dbl> <dbl>   <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>   <dbl>\n1     0.321        0.316 0.593    62.4 2.49e-53     5  -594. 1203. 1234.    232.\n# … with 2 more variables: df.residual <int>, nobs <int>, and abbreviated\n#   variable names ¹​adj.r.squared, ²​statistic, ³​deviance\n# ℹ Use `colnames()` to see all variable names\n\nplot(warblers_lm)\n\n\n\n\n\n\n\n\n\n\n\n\n## Model 2: DV is bird mass, predictor variables are:  tarsus length (mm), age of bird at capture, and sex. \nwarblers_lm2 <- lm(mass ~  tarsus1 + age_banded + sex, data = warblers_clean)\nsummary(warblers_lm2)\n\n\nCall:\nlm(formula = mass ~ tarsus1 + age_banded + sex, data = warblers_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.8935 -0.3683 -0.0179  0.3687  4.8730 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    8.95060    0.64792  13.814   <2e-16 ***\ntarsus1        0.08051    0.03416   2.357   0.0187 *  \nage_bandedASY  0.01871    0.14057   0.133   0.8942    \nage_bandedSY  -0.02246    0.13717  -0.164   0.8700    \nsexM          -0.78737    0.04924 -15.990   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.602 on 662 degrees of freedom\nMultiple R-squared:  0.2979,    Adjusted R-squared:  0.2937 \nF-statistic: 70.22 on 4 and 662 DF,  p-value: < 2.2e-16\n\nAIC(warblers_lm2) # 1222.922\n\n[1] 1222.922\n\nvif(warblers_lm2)\n\n               GVIF Df GVIF^(1/(2*Df))\ntarsus1    1.040369  1        1.019985\nage_banded 1.076407  2        1.018578\nsex        1.115105  1        1.055985\n\nplot(warblers_lm2)\n\n\n\n\n\n\n\n\n\n\n\n\nwarblers_lm_fit2 <- glance(warblers_lm2)\n\n## Model 3: DV is bird mass, predictor variables are: age of bird at capture, and sex. \nwarblers_lm3 <- lm(mass ~ age_banded + sex, data = warblers_clean)\nsummary(warblers_lm3)\n\n\nCall:\nlm(formula = mass ~ age_banded + sex, data = warblers_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9179 -0.3566 -0.0179  0.3476  4.8476 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   10.44619    0.13183  79.242   <2e-16 ***\nage_bandedASY  0.01038    0.14101   0.074    0.941    \nage_bandedSY  -0.02827    0.13762  -0.205    0.837    \nsexM          -0.76550    0.04853 -15.775   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6041 on 663 degrees of freedom\nMultiple R-squared:  0.292, Adjusted R-squared:  0.2888 \nF-statistic: 91.15 on 3 and 663 DF,  p-value: < 2.2e-16\n\nAIC(warblers_lm3) # 1226.497\n\n[1] 1226.497\n\nvif(warblers_lm3)\n\n               GVIF Df GVIF^(1/(2*Df))\nage_banded 1.075537  2        1.018372\nsex        1.075537  1        1.037081\n\nplot(warblers_lm3)\n\n\n\n\n\n\n\n\n\n\n\n\nwarblers_lm_fit3 <- glance(warblers_lm3)\n\n# Histograms\nggplot(data = warblers_clean, aes(x = mass)) +\n  geom_histogram(bins = 15) +\n  facet_wrap(~sex, scales = \"free\")\n\n\n\n# QQ Plots\nggplot(data= warblers_clean, aes(sample = mass)) +\n  geom_qq() +\n  facet_wrap(~sex)\n\n\n\n\n\nRegression table\nstargazer(warblers_lm, type = \"html\")\n\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nmass\n\n\n\n\n\n\n\n\nwing_r\n\n\n0.074***\n\n\n\n\n\n\n(0.016)\n\n\n\n\n\n\n\n\n\n\ntarsus1\n\n\n0.074**\n\n\n\n\n\n\n(0.034)\n\n\n\n\n\n\n\n\n\n\nage_bandedASY\n\n\n-0.005\n\n\n\n\n\n\n(0.138)\n\n\n\n\n\n\n\n\n\n\nage_bandedSY\n\n\n0.016\n\n\n\n\n\n\n(0.135)\n\n\n\n\n\n\n\n\n\n\nsexM\n\n\n-1.043***\n\n\n\n\n\n\n(0.073)\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n4.613***\n\n\n\n\n\n\n(1.118)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n667\n\n\n\n\nR2\n\n\n0.321\n\n\n\n\nAdjusted R2\n\n\n0.316\n\n\n\n\nResidual Std. Error\n\n\n0.593 (df = 661)\n\n\n\n\nF Statistic\n\n\n62.442*** (df = 5; 661)\n\n\n\n\n\n\n\n\nNote:\n\n\np<0.1; p<0.05; p<0.01\n\n\n\n\n\n\nModel Selection and Justification\nModel 1: DV is bird mass, predictor variables are: right wing length (mm), tarsus length (mm), age of bird at capture, and sex. (I have selected this one as the final model). Model 2: DV is bird mass, predictor variables are: tarsus length (mm), age of bird at capture, and sex. Model 3: DV is bird mass, predictor variables are: age of bird at capture, and sex.\n\nWarblers data set is normally distributed for mass with respect to sex.\nWhen looking at the Residual Variances, for Homoscedasticity, it appears residuals appear more randomly distributed evenly around the horizontal dotted line compared to model 2 and model 3.\nResidual plots and Q-Q plots visually show that model 1 meets the homoscedasticity and normality assumptions of linear regression.\nAIC score for model 1 was the lowest (1202.8) compared to model 2 (1222.92) and 3 (1226.5).\nConceptually, including predictor variables like wing length, tarsus length, age of bird capture and sex indicate a stronger correlation to bird mass (0.32). The adjusted R2 value here (0.32) indicates that 32 % of variance in body mass is explained by these variables included in the model.\n\n\nInterpreting given coeffients in Model 1:\n\nThe slope of the linear model was 0.0739 for right wing length (mm), 0.0743 for tarsus length (mm), -0.052 for age of bird at capture, -1.043 for sex, and the y-intercept was 4.613. This suggests that on average, we expect that bird body mass (g) to increase by 0.0739 grams for each 1 mm of increase in right wing length. We expect bird body mass to increase by 0.0743 grams for each 1 mm of increase in bird tarsus length.\n\n\n\nBlack-throated blue warbler data source:\n\nRodenhouse, N., R. Holmes, S. Sillett, and M. Webster. 2019. Black-throated Blue Warbler capture histories, Hubbard Brook Experimental Forest, 1986 - 2010 ver 4. Environmental Data Initiative. https://doi.org/10.6073/pasta/ea985022acfdb76cd7beeaf8da6c39b1"
  },
  {
    "objectID": "posts/2021-09-18-juvenile-snowshoe-hares-exploration/juvenile-snowshoe-hares-exploration.html",
    "href": "posts/2021-09-18-juvenile-snowshoe-hares-exploration/juvenile-snowshoe-hares-exploration.html",
    "title": "Juvenile snowshoe hares exploration",
    "section": "",
    "text": "the snowshoe hares data can be found in the data folder of this repo; the Rmd and html files can be found in the src folder\nthe qmd format can be found here"
  },
  {
    "objectID": "posts/2021-09-18-juvenile-snowshoe-hares-exploration/juvenile-snowshoe-hares-exploration.html#exploratory-findings",
    "href": "posts/2021-09-18-juvenile-snowshoe-hares-exploration/juvenile-snowshoe-hares-exploration.html#exploratory-findings",
    "title": "Juvenile snowshoe hares exploration",
    "section": "1. Exploratory findings",
    "text": "1. Exploratory findings\n\nAnnual juvenile hare trap counts\n\n## from the original hares df, mutate to make new columns of the date and then years\n## filter by juveniles \n## group by year\n## report those counts of juveniles by year \nhares_juvinile <- hares %>%   \n  mutate(Date = mdy(date))%>% \n  mutate(Year = year(Date)) %>% \n  filter(age == \"j\") %>% \n  group_by(Year) %>% \n  count()\n\n\n## make a simple line graph of year vs count of the juvenile hare trap counts\nggplot(data = hares_juvinile,\n       aes(x=Year, y= n)) + \n  geom_line(col= \"red\")  +\n  geom_point(col = \"red\") +\n  theme_minimal() +\n  labs(x= \"Year\", \n       y='Count of hare trappings') +\n  scale_x_continuous(breaks=seq(1999, 2012, 2)) \n\n\n\n\nFigure 2. Annual juvenile hare trap counts (1999 - 2012)\n\n\n\n# mean(hares_juvinile$n)  #to see the mean of counts from the  hares_juvinile df\n# median(hares_juvinile$n) #to see the median of counts from the  hares_juvinile df\n\n\nMajor takeaways from Figure 2:\nThe max count of juvenile hare trappings was 126 in 1999. The min count of 2 juvenile hare trappings in 2010. The mean annual number of juvenile hares trapped was 31.5. The median annual number of juvenile hares trapped is 18.5. More generally, in more recent years (2005-2012), hare trapping have fluctuated quite a bit showing sharp increases followed by decreases."
  },
  {
    "objectID": "posts/2021-09-18-juvenile-snowshoe-hares-exploration/juvenile-snowshoe-hares-exploration.html#visualization-of-juvenile-hare-weights.",
    "href": "posts/2021-09-18-juvenile-snowshoe-hares-exploration/juvenile-snowshoe-hares-exploration.html#visualization-of-juvenile-hare-weights.",
    "title": "Juvenile snowshoe hares exploration",
    "section": "2. Visualization of juvenile hare weights.",
    "text": "2. Visualization of juvenile hare weights.\n\nhares_weight <- hares %>% \n  filter(age == \"j\") %>% \n  select(c(\"grid\", \"sex\", \"weight\")) \n\nhares_weight$grid <- as.factor(hares_weight$grid)\ngrid.labs <- c(\"Bonbs\", \"Bonmat\", \"Bonrip\")\nnames(grid.labs) <- c(\"bonbs\", \"bonmat\", \"bonrip\")\n\nggplot(hares_weight, \n       aes(x=sex, y= weight)) +\n  geom_boxplot(aes(fill=sex)) +\n  facet_wrap(~grid, labeller = labeller(grid = grid.labs)) + \n  theme_minimal() +\n  labs(x= \"Sex\", \n       y='Weight (g)') +\n  scale_x_discrete(labels= c(\"Female\", \"Male\", \"NA\")) + \n  scale_y_continuous(breaks=seq(0, 1700, 300)) +\n  theme(legend.position = \"none\")\n\n\n\n\nFigure 3. Mean weight observations (g) for juvenile snowhoe hare weights of the three differnt sites (Bonbs, Bonmat, and Bonrip) from 1999 to 2012. With regards to color: pink (female), blue (male) and grey (NA). Box endpoints indicate the 25th and 75th percentile values; the black line indicate the median value for each sex.\n\n\n\n\n\nMajor takeaways from Figure 3\nThis graph depicts juvenile hare weight by sex across the three sites. Site bonbs has the max weight for both male and female hares. In contrast, site bonrip has the lowest weight of female and male hares. Additionally, this graph depicts the upper and lower quartiles of each sex at the different sites. This graph also includes NA values."
  },
  {
    "objectID": "posts/2021-09-18-juvenile-snowshoe-hares-exploration/juvenile-snowshoe-hares-exploration.html#juvenile-weight-comparison-of-male-female-snowshoe-hares",
    "href": "posts/2021-09-18-juvenile-snowshoe-hares-exploration/juvenile-snowshoe-hares-exploration.html#juvenile-weight-comparison-of-male-female-snowshoe-hares",
    "title": "Juvenile snowshoe hares exploration",
    "section": "3. Juvenile weight comparison of male & female snowshoe hares",
    "text": "3. Juvenile weight comparison of male & female snowshoe hares\n\nhares_weight_mf <- hares %>% \n  filter(age == \"j\") %>% \n  select(c(\"sex\", \"weight\")) %>% \n  group_by(sex) %>% \n  summarise(mean_weight = mean(weight, na.rm=T),\n            sd_weight = sd(weight, na.rm=T),\n            n = n())\n\nhares_weight_mf %>%  \n  kable(col.names = c(\"Sex\",\n                      \"Mean weight (g)\",\n                      \"Standard deviation\",\n                      \"Sample size (n)\"), \n        caption = \"**Table 1**: summary statistics of juvenile male and female snowshoe hare 1999 - 2012\") %>% \n  kable_styling(full_width = FALSE) \n\n\n\n**Table 1**: summary statistics of juvenile male and female snowshoe hare 1999 - 2012\n \n  \n    Sex \n    Mean weight (g) \n    Standard deviation \n    Sample size (n) \n  \n \n\n  \n    f \n    855.3909 \n    292.2526 \n    200 \n  \n  \n    m \n    945.8589 \n    333.2151 \n    163 \n  \n  \n    NA \n    614.5455 \n    357.5853 \n    15 \n  \n\n\n\n\n\n\n# Histograms\nggplot(data = hares, aes(x = weight)) +\n  geom_histogram(bins = 15) +\n  facet_wrap(~sex, scales = \"free\")\n\nWarning: Removed 515 rows containing non-finite values (stat_bin).\n\n\n\n\n# QQ Plots\nggplot(data= hares, aes(sample = weight)) +\n  geom_qq() +\n  facet_wrap(~sex)\n\nWarning: Removed 515 rows containing non-finite values (stat_qq).\n\n\n\n\n# two sample t-test\nhares_weight_f <- hares %>% \n  select(c(\"sex\", \"weight\")) %>% \n  filter(sex == \"f\") %>% \n  pull(weight)\n\nhares_weight_m <- hares %>% \n  select(c(\"sex\", \"weight\")) %>% \n  filter(sex == \"m\") %>% \n  pull(weight)\n\nt.test(hares_weight_f, hares_weight_m)\n\n\n    Welch Two Sample t-test\n\ndata:  hares_weight_f and hares_weight_m\nt = 0.85568, df = 2428.6, p-value = 0.3923\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -14.61684  37.24934\nsample estimates:\nmean of x mean of y \n 1359.448  1348.131 \n\n# cohens d/ effect size\ncohen.d(hares_weight_f, hares_weight_m, na.rm = TRUE)\n\n\nCohen's d\n\nd estimate: 0.03389279 (negligible)\n95 percent confidence interval:\n      lower       upper \n-0.04522614  0.11301172 \n\n\n\nMajor takeaway from means comparison output:\nMale snowshoe juvenile hares had the larger mean (945.8589 ± 333.2151, n = 163; mean ± 1 standard deviation), compared to snowshoe female juvenile hares which had a smaller mean (855.3909 ± 292.2526, n = 200; mean ± 1 standard deviation). The actual difference in means from juvenile male and female snowshoe hares is 11.317. The outcomes of the two sample t-test indicates there is a pretty decent chance (40%) of randomly selecting two samples from populations with the same mean that are this different by chance. In sum, the difference in means is not significant (Welch’s two-sample t-test: t(2428.6) = 0.85568, p > 0.001), and the effect size is negligible (Cohen’s d = 0.0334)."
  },
  {
    "objectID": "posts/2021-09-18-juvenile-snowshoe-hares-exploration/juvenile-snowshoe-hares-exploration.html#examining-relationship-between-juvenile-weight-hind-foot-length.",
    "href": "posts/2021-09-18-juvenile-snowshoe-hares-exploration/juvenile-snowshoe-hares-exploration.html#examining-relationship-between-juvenile-weight-hind-foot-length.",
    "title": "Juvenile snowshoe hares exploration",
    "section": "4. Examining relationship between juvenile weight & hind foot length.",
    "text": "4. Examining relationship between juvenile weight & hind foot length.\n\nhares_hind <- hares %>% \n  filter(age == \"j\") %>% \n  select(c(\"weight\", \"hindft\"))\n\n\nggplot(hares_hind, \n       aes(x=weight, y=hindft)) + \n  geom_point() +\n  theme_minimal() +\n  labs(x= \"Weight (g)\", \n       y='Hind foot length (mm)') + \n  scale_x_continuous(breaks=seq(0, 1800, 400)) \n\n\n\n\nFigure 4. Juvenile hare weights vs hind foot length from 1999 - 2012"
  },
  {
    "objectID": "posts/2021-09-18-juvenile-snowshoe-hares-exploration/juvenile-snowshoe-hares-exploration.html#linear-model-output",
    "href": "posts/2021-09-18-juvenile-snowshoe-hares-exploration/juvenile-snowshoe-hares-exploration.html#linear-model-output",
    "title": "Juvenile snowshoe hares exploration",
    "section": "5. Linear model output",
    "text": "5. Linear model output\n\n## linear regression \nhares_lm <- lm(weight ~ hindft, data = hares_hind)\n\n# Return the complete overview:\nsummary(hares_lm)\n\n\nCall:\nlm(formula = weight ~ hindft, data = hares_hind)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-661.1 -108.2   17.0  164.2  737.5 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -279.3419   115.4811  -2.419   0.0163 *  \nhindft         9.5234     0.9283  10.259   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 263.9 on 247 degrees of freedom\n  (129 observations deleted due to missingness)\nMultiple R-squared:  0.2988,    Adjusted R-squared:  0.2959 \nF-statistic: 105.2 on 1 and 247 DF,  p-value: < 2.2e-16\n\n# We can use the broom::tidy() function to get the model outputs in nice data frame format:\nhares_lm_tidy <- broom::tidy(hares_lm)\n\n# Get the intercept: \nhares_int <- hares_lm_tidy$estimate[1]\nhares_int\n\n[1] -279.3419\n\n# Then to get the flipper_length coefficient:\nhares_coef <- hares_lm_tidy$estimate[2]\nhares_coef\n\n[1] 9.523399\n\n#What about getting some other model information (degrees of freedom, F-statistic, p-value, etc.)?\n#Many of these statistical outcomes can be accessed more easily using broom::glance().\n# Metrics at a glance: \nhares_lm_out <- broom::glance(hares_lm)\nhares_lm_out\n\n# A tibble: 1 × 12\n  r.squared adj.r.squa…¹ sigma stati…²  p.value    df logLik   AIC   BIC devia…³\n      <dbl>        <dbl> <dbl>   <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>   <dbl>\n1     0.299        0.296  264.    105. 8.46e-21     1 -1741. 3487. 3498.  1.72e7\n# … with 2 more variables: df.residual <int>, nobs <int>, and abbreviated\n#   variable names ¹​adj.r.squared, ²​statistic, ³​deviance\n# ℹ Use `colnames()` to see all variable names\n\n# Explore model assumptions\nplot(hares_lm)\n\n\n\n\n\n\n\n\n\n\n\n\n# Pearson’s r\nhares_cor <- cor.test(hares_hind$weight, hares_hind$hindft)\nhares_cor\n\n\n    Pearson's product-moment correlation\n\ndata:  hares_hind$weight and hares_hind$hindft\nt = 10.259, df = 247, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.4530683 0.6282259\nsample estimates:\n      cor \n0.5465982 \n\n\n\n# Visualize the model\nggplot(data = hares_hind, aes(x = weight, y = hindft)) +\n  geom_point(size = 2) +\n  geom_smooth(method = \"lm\",\n              color = \"red\",\n              size = 0.5,\n              fill = \"gray10\",\n              alpha = 0.5) +\n  theme_light() +\n  ggpubr::stat_regline_equation(label.x = 230, label.y = 160) +\n  labs(x= \"Weight (g)\", \n       y='Hind foot length (mm)')\n\n\n\n\nFigure 5. Linear model of weight (g) vs hind foot length (mm) in juvenile snowshoe hare (1999 - 2012)\n\n\n\n\n\nOutcomes of linear regression:\nSimple linear regression was used to explore between juvenile snowshoe hare weight (g) and hare hind foot length (mm) across all sites, and including both male and female snowshoe hares. A significant regression model was found (\\(\\beta\\) = 9.523, F(1,247) = 105.2, p < 0.001) with an R2 of 0.299. The slope of the linear model is 9.523 and the y-intercept is -279.3. This slope of the linear model suggests that on average, we expect that weight to increase by 9.523 grams for each 1 mm of increase in hind foot length. Additionally, when conducting a linear model, there are assumptions such as, linearly related variables, normally distributed, Homoscedasticity and iid residuals (no serial correlation). When looking at the Residual Variances, for Homoscedasticity, it appears residuals do not appear randomly distributed evenly around the horizontal dotted line. Additionally, in the QQ plot, the residuals do not appear to be entirely normally distributed – theres quite a few points on the tails that drift from the dotted line. This is probably partly why we see a more moderate R value (0.547).\n\n\nSummary of juvenile hares exploration:\n\nThe max count of juvenile hare trappings was 126 in 1999. The min count of juvenile hare trappings was 2 in 2010. The mean annual number of juvenile hares trapped was 31.5. The median annual number of juvenile hares trapped is 18.5. More generally, in more recent years (2005-2012), hare trapping have fluctuated quite a bit showing sharp increases followed by decreases.\nThe actual difference in means from juvenile male and female snowshoe hares is 11.317. The outcomes of the two sample t-test indicates there is a pretty decent chance (40%) of randomly selecting two samples from populations with the same mean that are this different by chance. The cohend d (effect size) is 0.03389279, a negligible effect size.\nThis slope of the linear model suggests that on average, we expect that weight to increase by 9.523 grams for each 1 mm of increase in juvenile hind foot length.\nObtained a moderate persons r = 0.547 value between weights and hind foot length\n\n\n\nCitations:\n\nKielland, K., F.S. Chapin, R.W. Ruess, and Bonanza Creek LTER. 2017. Snowshoe hare physical data in Bonanza Creek Experimental Forest: 1999-Present ver 22. Environmental Data Initiative. https://doi.org/10.6073/pasta/03dce4856d79b91557d8e6ce2cbcdc14\nLink to metadata: https://portal.edirepository.org/nis/metadataviewer?packageid=knb-lter-bnz.55.22"
  },
  {
    "objectID": "posts/2021-03-07-cetacean-richness/cetacean-richness.html",
    "href": "posts/2021-03-07-cetacean-richness/cetacean-richness.html",
    "title": "Species Richness of Cetaceans along Coastal California",
    "section": "",
    "text": "Load Packages\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(here)\n\nhere() starts at /Users/elmeraa/Desktop/elmera/elmera\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(sf)\n\nLinking to GEOS 3.10.2, GDAL 3.4.2, PROJ 8.2.1; sf_use_s2() is TRUE\n\nlibrary(raster)\n\nLoading required package: sp\n\nAttaching package: 'raster'\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\nlibrary(fasterize)\n\n\nAttaching package: 'fasterize'\n\nThe following object is masked from 'package:graphics':\n\n    plot\n\nThe following object is masked from 'package:base':\n\n    plot\n\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\nlibrary(rgeos)\n\nrgeos version: 0.5-9, (SVN revision 684)\n GEOS runtime version: 3.10.2-CAPI-1.16.0 \n Please note that rgeos will be retired by the end of 2023,\nplan transition to sf functions using GEOS at your earliest convenience.\n GEOS using OverlayNG\n Linking to sp version: 1.4-7 \n Polygon checking: TRUE \n\n\n\n\nRead in data and stack files\n\ncetacean <-  list.files(here(\"posts\", \"2021-03-07-cetacean-richness\",\"ca_cetaceans\"), full.names = TRUE)\ncetacean_raster <- stack(cetacean)\ncetacean_raster\n\nclass      : RasterStack \ndimensions : 12, 20, 240, 35  (nrow, ncol, ncell, nlayers)\nresolution : 0.5, 0.5  (x, y)\nextent     : -125, -115, 32, 38  (xmin, xmax, ymin, ymax)\ncrs        : +proj=longlat +datum=WGS84 +no_defs \nnames      : Balaenoptera_acutorostrata, Balaenoptera_borealis, Balaenoptera_brydei, Balaenoptera_edeni, Balaenoptera_musculus, Balaenoptera_physalus, Berardius_bairdii, Delphinus_capensis, Delphinus_delphis, Eschrichtius_robustus, Eubalaena_japonica, Globicephala_macrorhynchus, Grampus_griseus, Indopacetus_pacificus, Kogia_breviceps, ... \nmin values :                       0.11,                  0.02,                0.03,               0.03,                  0.01,                  0.06,              0.01,               0.03,              0.03,                  0.11,               0.59,                       0.02,            0.03,                  0.01,            0.03, ... \nmax values :                       1.00,                  1.00,                1.00,               1.00,                  1.00,                  1.00,              1.00,               0.63,              1.00,                  1.00,               1.00,                       1.00,            1.00,                  0.47,            1.00, ... \n\nplot(cetacean_raster)\n\n\n\n\n\n\nApply probability threshold (of 0.6 or greater) to determine presence or non-presence\n\naquamap_fun <- function(x, thresh = 0.6){\n  y <- ifelse(x >= thresh, 1, 0)\n  return(y)\n}\n\naquamap <- calc(cetacean_raster, fun = aquamap_fun)\nspecies_richness1 <- calc(aquamap, fun = sum, na.rm = TRUE)\nplot(species_richness1)\n\n\n\n\n\n\nConverting to dataframe and plotting\n\naquamap_df <- raster::rasterToPoints(species_richness1) %>% \n  as.data.frame()\n\nstates110 <- ne_download(scale = 110, type = 'states', category = 'cultural', returnclass = \"sf\") %>% filter(name %in% c(\"California\"))\n\nWarning in check_data_exist(scale = scale, category = category, type = type):\nyour combination of type, category, scale seem not to exist in the list of\nNatural Earth data so you may get a download fail message. Check ?ne_download or\nhttp://www.naturalearthdata.com/features/ to see data availability.\n\nWarning in check_data_exist(scale = scale, category = category, type = type):\nyour combination of type, category, scale seem not to exist in the list of\nNatural Earth data so you may get a download fail message. Check ?ne_download or\nhttp://www.naturalearthdata.com/features/ to see data availability.\n\n\nOGR data source with driver: ESRI Shapefile \nSource: \"/private/var/folders/r0/gbtncpg92w3chydzw5fw5bnr0000gn/T/Rtmp0dFxl2\", layer: \"ne_110m_admin_1_states_provinces_lakes\"\nwith 51 features\nIt has 121 fields\nInteger64 fields read as strings:  ne_id \n\nggplot() +\ngeom_raster(data = aquamap_df, aes(x=x,y=y, fill = layer)) +\n  geom_sf(data = states110) +\n  scale_fill_gradient2(low = \"red\", mid = \"white\", high = \"blue\") +\n  labs(x = \"Longitude\", y = \"Latitude\", title = \"Species Richness of Cetaceans along Coastal California\", fill = \"Number of Cetacean Species\") +\n  theme_classic()\n\n\n\n\nFig. 1 Species Richness of 16 Cetacean Species along the Coast of California. Presence of Cetacean species was determined with with a probability threshold of 0.6 or greater.\n\n\n\n\n\n\nCitation:\n\nKaschner, K., Rius-Barile, J., Kesner-Reyes, K., Garilao, C., Kullander, S., Rees, T., & Froese, R. (2016). AquaMaps: Predicted range maps for aquatic species. www.aquamaps.org"
  },
  {
    "objectID": "posts/2021-05-04-diffusion/diffusion.html",
    "href": "posts/2021-05-04-diffusion/diffusion.html",
    "title": "Dimentional Diffusion",
    "section": "",
    "text": "the diffusion R script can be found in the folder of this repo"
  },
  {
    "objectID": "posts/2021-05-04-diffusion/diffusion.html#load-packages",
    "href": "posts/2021-05-04-diffusion/diffusion.html#load-packages",
    "title": "Dimentional Diffusion",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(tidyverse)\nlibrary(deSolve)\nlibrary(here)"
  },
  {
    "objectID": "posts/2021-05-04-diffusion/diffusion.html#r-implementation",
    "href": "posts/2021-05-04-diffusion/diffusion.html#r-implementation",
    "title": "Dimentional Diffusion",
    "section": "R implementation",
    "text": "R implementation\n\nsource(here(\"posts/2021-05-04-diffusion/R\",\"diffusion.R\"))\n\n# run our diffusion model (iterative difference equation) with initial concentration of 10, for 8 timestep (size 1m), and 10 space steps (size 1s)\n# using diffusion parameters 0.5 s/m2, 10 m2\nresult = diff1(initialC=10, nx=10, dx=1, nt=8, dt=1, D=0.5, area=10)\n\n# a list is returned with our 3 data frames for concentration (conc), qin and qout\n# result\n\n# used filled contour to plot results\n# head(result$conc)\nfilled.contour(result$conc, xlab=\"Time\", ylab=\"Distance\")\n\n\n\n# or if you prefer this orientation (Distance on x axis)\nfilled.contour(t(result$conc), ylab=\"Time\", xlab=\"Distance\")"
  },
  {
    "objectID": "posts/2021-05-04-diffusion/diffusion.html#change-parameters-diffusivity-d-and-space-and-time-steps-dx-dt",
    "href": "posts/2021-05-04-diffusion/diffusion.html#change-parameters-diffusivity-d-and-space-and-time-steps-dx-dt",
    "title": "Dimentional Diffusion",
    "section": "Change parameters (diffusivity D, and space and time steps (dx, dt))",
    "text": "Change parameters (diffusivity D, and space and time steps (dx, dt))\n\n# changes diffusivity and other parameters particularly\n# diffusivity, dx and dt\nres=diff1(initialC=10,nx=5,dx=25,nt=20,dt=20,D=0.75,area=10) \n\nfilled.contour(res$conc, xlab=\"Time (fraction of hour)\",ylab=\"Distance Along Path (m)\", main=\"Pollutant Diffusion\")\n\n\n\n# we can also see how much material moved from place to place each time step\nfilled.contour(res$qin, xlab=\"Time (fraction of hour)\",ylab=\"Distance Along Path (m)\", main = \"Qin\")"
  },
  {
    "objectID": "posts/2021-05-04-diffusion/diffusion.html#summary",
    "href": "posts/2021-05-04-diffusion/diffusion.html#summary",
    "title": "Dimentional Diffusion",
    "section": "Summary",
    "text": "Summary\nwe can see an overall increase in total simulation time (nt * dt) which lead to an increase in the pollutant over time and space. However, decreasing the number of discrete segments (m) lead to greater distance of the pollutant along the path."
  },
  {
    "objectID": "posts/2021-03-07-hierarchical-clustering/hierarchical-clustering.html",
    "href": "posts/2021-03-07-hierarchical-clustering/hierarchical-clustering.html",
    "title": "Hierarchical Clustering",
    "section": "",
    "text": "the stream chemistry data can be found in the data folder of this repo; the Rmd and html files, denoted as a4-task1, can be found in the src folder\nthe qmd format can be found here"
  },
  {
    "objectID": "posts/2021-03-07-hierarchical-clustering/hierarchical-clustering.html#load-packages",
    "href": "posts/2021-03-07-hierarchical-clustering/hierarchical-clustering.html#load-packages",
    "title": "Hierarchical Clustering",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\n# Packages for cluster analysis:\nlibrary(NbClust)\nlibrary(cluster)\nlibrary(factoextra)\nlibrary(dendextend)\nlibrary(ggdendro)\n\n\nIntroduction:\n\nTo perform hierarchical clustering by site, we’ll begin by making a data frame that has a single summary row per site (e.g. based on means from all observations at that site), then we will calculate the euclidean distance before performing complete linkage agglomerative hierarchical clustering.\n\n\n\nRead in data\n\nstream_chem <- read_csv(here(\"posts\", \"2021-03-07-hierarchical-clustering\",\"sbc_lter_registered_stream_chemistry.csv\")) %>% \n  clean_names() %>% \n  na_if(-999.0) %>% \n  group_by(site_code) %>% \n  summarise(across(nh4_u_m:spec_cond_u_spercm, mean, na.rm = TRUE)) %>% \n  drop_na()\n\nRows: 19390 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (1): site_code\ndbl  (10): nh4_uM, no3_uM, po4_uM, tdn_uM, tdp_uM, tpc_uM, tpn_uM, tpp_uM, t...\ndttm  (1): timestamp_local\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nScale the data\n\n# scale the numeric variables\nstream_chem_scaled <- stream_chem %>% \n  dplyr::select(2:11) %>% \n  scale()\n\n# make rownames the site code names from original data set\nrownames(stream_chem_scaled) <- stream_chem$site_code\n\n# Compute dissimilarity values (Euclidean distances):\nstream_euc_distance <- dist(stream_chem_scaled, method = \"euclidean\")\n\n# Check out the output:\n# View(euc_distance)\n\n\n\nPerform hierarchical clustering by complete linkage with stats::hclust()\n\n# Hierarchical clustering (complete linkage)\nstream_hc_complete <- hclust(stream_euc_distance, method = \"complete\" )\n\n# Plot it (base plot):\nplot(stream_hc_complete, cex = 0.6, hang = -1)\n\n\n\n\n\n\nConvert to class: dendogram\n\nstream_dend_complete <- as.dendrogram(stream_hc_complete)\n\n\n\nPlot using ggdendrogram(), a ggplot wrapper:\n\n# ggplot \nggdendrogram(stream_dend_complete, \n             rotate = TRUE)+\n  labs(x = \"Santa Barbara area watershed site code\") +\n  ylab(NULL)+ \n  theme_bw() + \n  theme(panel.border = element_blank(), panel.grid.major = element_blank(),\npanel.grid.minor = element_blank(), axis.line = element_line(colour = \"black\")) \n\n\n\n\n\n\nData & Metadata Source:\n\nSBC LTER: Stream chemistry in the Santa Barbara Coastal drainage area, ongoing since 2000 Creators: Santa Barbara Coastal LTER, & Melack, John M Citation: Santa Barbara Coastal LTER and J. Melack. 2019. SBC LTER: Land: Stream chemistry in the Santa Barbara Coastal drainage area, ongoing since 2000 ver 16. Environmental Data Initiative. https://doi.org/10.6073/pasta/67a558a24ceed9a0a5bf5e46ab841174."
  },
  {
    "objectID": "posts/2021-02-23-blrpalmetto/blrpalmetto.html",
    "href": "posts/2021-02-23-blrpalmetto/blrpalmetto.html",
    "title": "Binary Logistic Regression",
    "section": "",
    "text": "the palmetto data can be found in the data folder of this repo; the Rmd and html files, denoted as a2-task2, can be found in the src folder\nthe qmd format can be found here"
  },
  {
    "objectID": "posts/2021-02-23-blrpalmetto/blrpalmetto.html#load-packages",
    "href": "posts/2021-02-23-blrpalmetto/blrpalmetto.html#load-packages",
    "title": "Binary Logistic Regression",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(GGally)\nlibrary(broom)\nlibrary(jtools)\nlibrary(kableExtra)"
  },
  {
    "objectID": "posts/2021-02-23-blrpalmetto/blrpalmetto.html#read-in-data",
    "href": "posts/2021-02-23-blrpalmetto/blrpalmetto.html#read-in-data",
    "title": "Binary Logistic Regression",
    "section": "Read in data",
    "text": "Read in data\n\npalmetto <- read_csv(here(\"posts\", \"2021-02-23-blrpalmetto\", \"palmetto.csv\"), \n                     col_types = cols(.default = \"c\")) %>%\n  mutate(height = as.numeric(height)) %>% \n  mutate(species_name = case_when(\n    species == 1 ~ \"Serenoa repens\", \n    species == 2 ~ \"Sabal etonia\")) %>% \n  mutate(site_name = case_when(\n    site == 1 ~ \"Copse Road\", \n    site == 2 ~ \"Ridge Road\",\n    site == 3 ~ \"WSP2\",\n    site == 4 ~ \"WS30\",\n    site == 5 ~ \"WSP1\",\n    site == 6 ~ \"Red Hill\"))  %>% \n  mutate(width = as.integer(width)) %>% \n  mutate(length = as.integer(length)) %>% \n  mutate(green_lvs = as.integer(green_lvs))"
  },
  {
    "objectID": "posts/2021-02-23-blrpalmetto/blrpalmetto.html#data-exploration-between-species-1-serenoa-repens-and-species-2-sabal-etonia.",
    "href": "posts/2021-02-23-blrpalmetto/blrpalmetto.html#data-exploration-between-species-1-serenoa-repens-and-species-2-sabal-etonia.",
    "title": "Binary Logistic Regression",
    "section": "Data exploration between species 1 (Serenoa repens) and species 2 (Sabal etonia).",
    "text": "Data exploration between species 1 (Serenoa repens) and species 2 (Sabal etonia).\n\nggplot(palmetto,\n       aes(x = species_name, y = height)) +\n  geom_boxplot(aes(fill = species_name)) +\n  facet_wrap(~ site_name) +\n  labs(x = \"Species\", y = \"Canopy height (cm)\") +\n  scale_fill_discrete(name = \"Species\") +\n  theme_light() +\n theme(legend.position = \"top\")\n\n\n\n\nFigure 1. Species (Sabal etonia and Sernoa repens) vs canopy height (cm) by study site. Generally Sabal etonia tends to have higher canopy height than Serenoa repens across the sites."
  },
  {
    "objectID": "posts/2021-02-23-blrpalmetto/blrpalmetto.html#graph-2",
    "href": "posts/2021-02-23-blrpalmetto/blrpalmetto.html#graph-2",
    "title": "Binary Logistic Regression",
    "section": "Graph 2",
    "text": "Graph 2\n\nggplot(palmetto, aes(x = width, y = length)) +\n  geom_point(aes(color = species_name)) +\n  theme_minimal() +\n  labs(x = \"Canopy width (cm)\", y = \"Canopy height (cm)\") +\n  scale_color_discrete(name = \"Species\") +\n theme(legend.position = \"top\")\n\n\n\n\nFigure 2. Canopy width (cm) vs canopy height (cm) for both species (Sabal etonia and Serenoa repens). Trend indicates Sabal etonia trees tend to have more lower capopy width and higher canopy height as compared to Serenoa repens, however still lots of spread in the data."
  },
  {
    "objectID": "posts/2021-02-23-blrpalmetto/blrpalmetto.html#binary-logistic-regression-using-plant-height-canopy-length-canopy-width-and-green-leaves-as-predictor-variables-to-understand-how-they-relate-to-probability-of-a-plant-being-serenoa-repens-or-sabal-etonia",
    "href": "posts/2021-02-23-blrpalmetto/blrpalmetto.html#binary-logistic-regression-using-plant-height-canopy-length-canopy-width-and-green-leaves-as-predictor-variables-to-understand-how-they-relate-to-probability-of-a-plant-being-serenoa-repens-or-sabal-etonia",
    "title": "Binary Logistic Regression",
    "section": "Binary logistic regression using plant height, canopy length, canopy width and green leaves as predictor variables to understand how they relate to probability of a plant being Serenoa repens or Sabal etonia",
    "text": "Binary logistic regression using plant height, canopy length, canopy width and green leaves as predictor variables to understand how they relate to probability of a plant being Serenoa repens or Sabal etonia\n\npalmetto_blr_ds <- palmetto %>% \n  mutate(species_name = fct_drop(species_name)) %>% \n  select(species_name, height, length, width, green_lvs) \n  \npalmetto_blr <- glm(species_name ~ height + length + width + green_lvs ,\n                            data = palmetto_blr_ds, \n                            family = \"binomial\")"
  },
  {
    "objectID": "posts/2021-02-23-blrpalmetto/blrpalmetto.html#look-at-outcome-of-blr-model",
    "href": "posts/2021-02-23-blrpalmetto/blrpalmetto.html#look-at-outcome-of-blr-model",
    "title": "Binary Logistic Regression",
    "section": "Look at outcome of blr model",
    "text": "Look at outcome of blr model\n\npalmetto_blr #\n\n\nCall:  glm(formula = species_name ~ height + length + width + green_lvs, \n    family = \"binomial\", data = palmetto_blr_ds)\n\nCoefficients:\n(Intercept)       height       length        width    green_lvs  \n   -3.09204      0.02930     -0.04571     -0.03927      1.89280  \n\nDegrees of Freedom: 12266 Total (i.e. Null);  12262 Residual\n  (193 observations deleted due to missingness)\nNull Deviance:      17010 \nResidual Deviance: 5166     AIC: 5176\n\nsummary(palmetto_blr)\n\n\nCall:\nglm(formula = species_name ~ height + length + width + green_lvs, \n    family = \"binomial\", data = palmetto_blr_ds)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-4.7821  -0.2637  -0.0055   0.1715   3.3631  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -3.092041   0.141270  -21.89   <2e-16 ***\nheight       0.029304   0.002311   12.68   <2e-16 ***\nlength      -0.045713   0.001872  -24.41   <2e-16 ***\nwidth       -0.039266   0.002102  -18.68   <2e-16 ***\ngreen_lvs    1.892804   0.038591   49.05   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 17005.5  on 12266  degrees of freedom\nResidual deviance:  5166.1  on 12262  degrees of freedom\n  (193 observations deleted due to missingness)\nAIC: 5176.1\n\nNumber of Fisher Scoring iterations: 7\n\n# We can use the broom::tidy() function to get the model outputs in nice data frame format:\npalmetto_blr_tidy <- broom::tidy(palmetto_blr)\n\n# Get the intercept: \npalmetto_int <- palmetto_blr_tidy$estimate[1]\npalmetto_int\n\n[1] -3.092041\n\n# Then to get the  coefficient:\npalmetto_coef <- palmetto_blr_tidy$estimate[2]\npalmetto_coef\n\n[1] 0.02930385\n\n#What about getting some other model information (degrees of freedom, F-statistic, p-value, etc.)?\n#Many of these statistical outcomes can be accessed more easily using broom::glance().\n# Metrics at a glance: \npalmetto_lm_out <- broom::glance(palmetto_blr)\npalmetto_lm_out\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> <int>\n1        17006.   12266 -2583. 5176. 5213.    5166.       12262 12267\n\n## tidy model table output\npalmetto_blr_tidy %>% \n  kable(col.names = c(\"Term\",\n                      \"Estimate\",\n                      \"St Error\",\n                      \"t-statistic\",\n                      \"p-value\")) %>% \n  kable_styling(full_width = FALSE)\n\n\n\n \n  \n    Term \n    Estimate \n    St Error \n    t-statistic \n    p-value \n  \n \n\n  \n    (Intercept) \n    -3.0920409 \n    0.1412703 \n    -21.88740 \n    0 \n  \n  \n    height \n    0.0293039 \n    0.0023114 \n    12.67770 \n    0 \n  \n  \n    length \n    -0.0457129 \n    0.0018724 \n    -24.41353 \n    0 \n  \n  \n    width \n    -0.0392659 \n    0.0021022 \n    -18.67885 \n    0 \n  \n  \n    green_lvs \n    1.8928041 \n    0.0385905 \n    49.04843 \n    0 \n  \n\n\n\n\n\n\nWhat does model output tell us? Output tells us that probabiliy of Serenoa repens species because its “1” in the levels. So we expect on average, that as canopy height increases, the odds of the species being Serenoa repens increases. With an increase in canopy length, the odds of the species being Serenoa repens decreases on average. Similarly with width, we expect that as canopy width increases, the odds of the species being Serenoa repens decreases. Lastly, on average as count of green leaves increases, we expect the odds of the species being Serenoa repens increases."
  },
  {
    "objectID": "posts/2021-02-23-blrpalmetto/blrpalmetto.html#evaluates-how-successfully-this-model-would-classify-a-plant-as-the-correct-species-using-a-50-cutoff-e.g.-if-the-probability-is-50-that-it-is-species-a-then-it-would-be-classified-as-species-a",
    "href": "posts/2021-02-23-blrpalmetto/blrpalmetto.html#evaluates-how-successfully-this-model-would-classify-a-plant-as-the-correct-species-using-a-50-cutoff-e.g.-if-the-probability-is-50-that-it-is-species-a-then-it-would-be-classified-as-species-a",
    "title": "Binary Logistic Regression",
    "section": "Evaluates how successfully this model would “classify” a plant as the correct species, using a 50% cutoff (e.g. if the probability is >=50% that it is species A, then it would be classified as species A)",
    "text": "Evaluates how successfully this model would “classify” a plant as the correct species, using a 50% cutoff (e.g. if the probability is >=50% that it is species A, then it would be classified as species A)\n\npalmetto_blr_fitted <- palmetto_blr %>% \n  broom::augment(type.predict = \"response\") %>% \n  mutate(classification = case_when(.fitted >=0.50 ~ \"Serenoa repens\", \n      TRUE ~ \"Sabal etonia\")) \n  \n\npalmetto_table <- palmetto_blr_fitted %>% \n  select(species_name, .fitted, classification) %>% \n  mutate(correct = case_when(\n      species_name == \"Serenoa repens\" & classification == \"Serenoa repens\" ~ \"correct\",\n      species_name == \"Sabal etonia\" & classification == \"Sabal etonia\" ~ \"correct\",\n      TRUE ~ \"incorrect\"))\n  \n  \npalmetto_summary_table <- palmetto_table %>% \n  group_by(species_name, correct) %>% \n  summarise(count = n()) %>% \n  mutate(percentcorrect = (count / sum(count)*100))\n\n`summarise()` has grouped output by 'species_name'. You can override using the\n`.groups` argument.\n\npalmetto_summary_table %>%  \n  kable(col.names = c(\"Species name\",\n                      \"Correct or incorrect model classification?\",\n                      \"Count\",\n                      \"% Correctly classified\"), \n        caption = \"**Table 1**: summary statistics binary logistic regression analysis on palmetto dataset including species: Serenoa repens & Sabal etonia (data source: Abrahamson, W.G. 2019. Survival, growth and biomass estimates of two dominant palmetto species of south-central Florida from 1981 - 2017, ongoing at 5-year)\") %>% \n  kable_styling(full_width = FALSE) \n\n\n\n**Table 1**: summary statistics binary logistic regression analysis on palmetto dataset including species: Serenoa repens & Sabal etonia (data source: Abrahamson, W.G. 2019. Survival, growth and biomass estimates of two dominant palmetto species of south-central Florida from 1981 - 2017, ongoing at 5-year)\n \n  \n    Species name \n    Correct or incorrect model classification? \n    Count \n    % Correctly classified \n  \n \n\n  \n    Sabal etonia \n    correct \n    5688 \n    92.412673 \n  \n  \n    Sabal etonia \n    incorrect \n    467 \n    7.587327 \n  \n  \n    Serenoa repens \n    correct \n    5541 \n    90.657723 \n  \n  \n    Serenoa repens \n    incorrect \n    571 \n    9.342277"
  },
  {
    "objectID": "posts/2021-03-31-two-sample-t-test/two-sample-t-test.html",
    "href": "posts/2021-03-31-two-sample-t-test/two-sample-t-test.html",
    "title": "Two Sample T-Test",
    "section": "",
    "text": "library(tidyverse)\nlibrary(here)\nlibrary(broom)\nlibrary(effsize)\nlibrary(janitor)\nlibrary(kableExtra)\n\n\n\n\nthe sharkbay sea turtles data can be found in the exam_data folder of this repo; the Rmd and html files, denoted as azadpour_turtles, can be found in the task_code folder\nthe qmd format can be found here"
  },
  {
    "objectID": "posts/2021-03-31-two-sample-t-test/two-sample-t-test.html#read-in-sea-turtles-data-source-environmental-data-initiative",
    "href": "posts/2021-03-31-two-sample-t-test/two-sample-t-test.html#read-in-sea-turtles-data-source-environmental-data-initiative",
    "title": "Two Sample T-Test",
    "section": "Read in sea turtles data (source: Environmental Data Initiative)",
    "text": "Read in sea turtles data (source: Environmental Data Initiative)\n\nsea_turtles <- read_csv(here(\"posts\", \"2021-03-31-two-sample-t-test\", \"sharkbay_sea_turtles.csv\")) \nsea_turtles_clean <- sea_turtles %>% \n  dplyr::select(species, length, width, burr)"
  },
  {
    "objectID": "posts/2021-03-31-two-sample-t-test/two-sample-t-test.html#exploratory-visualization",
    "href": "posts/2021-03-31-two-sample-t-test/two-sample-t-test.html#exploratory-visualization",
    "title": "Two Sample T-Test",
    "section": "Exploratory visualization",
    "text": "Exploratory visualization\n\nggplot(sea_turtles_clean, aes(x = length,\n                              y= width)) +\n  geom_point() +\n  theme_minimal()+\n  labs(x =\"Curved carapace length at midline (cm)\", \n  y = \"Curved carapace width at widest point (cm)\")\n\nWarning: Removed 1 rows containing missing values (geom_point)."
  },
  {
    "objectID": "posts/2021-03-31-two-sample-t-test/two-sample-t-test.html#linear-regression",
    "href": "posts/2021-03-31-two-sample-t-test/two-sample-t-test.html#linear-regression",
    "title": "Two Sample T-Test",
    "section": "Linear Regression",
    "text": "Linear Regression\n\n## linear regression \nturtles_lm <- lm(length ~ width, data = sea_turtles_clean)\n\n# Return the complete overview:\nsummary(turtles_lm)\n\n\nCall:\nlm(formula = length ~ width, data = sea_turtles_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.1332  -2.6294   0.0433   2.4164  19.6729 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.16968    1.50479  -0.113     0.91    \nwidth        1.08061    0.01749  61.775   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.802 on 280 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.9316,    Adjusted R-squared:  0.9314 \nF-statistic:  3816 on 1 and 280 DF,  p-value: < 2.2e-16\n\n# We can use the broom::tidy() function to get the model outputs in nice data frame format:\nturtles_lm_tidy <- broom::tidy(turtles_lm)\n\n# Get the intercept: \nturtles_int <- turtles_lm_tidy$estimate[1]\nturtles_int\n\n[1] -0.1696804\n\n# Then to get the flipper_length coefficient:\nturtles_coef <- turtles_lm_tidy$estimate[2]\nturtles_coef\n\n[1] 1.080611\n\n#What about getting some other model information (degrees of freedom, F-statistic, p-value, etc.)?\n#Many of these statistical outcomes can be accessed more easily using broom::glance().\n# Metrics at a glance: \nturtles_lm_out <- broom::glance(turtles_lm)\nturtles_lm_out\n\n# A tibble: 1 × 12\n  r.squared adj.r.squ…¹ sigma stati…²   p.value    df logLik   AIC   BIC devia…³\n      <dbl>       <dbl> <dbl>   <dbl>     <dbl> <dbl>  <dbl> <dbl> <dbl>   <dbl>\n1     0.932       0.931  3.80   3816. 3.66e-165     1  -776. 1558. 1568.   4048.\n# … with 2 more variables: df.residual <int>, nobs <int>, and abbreviated\n#   variable names ¹​adj.r.squared, ²​statistic, ³​deviance\n# ℹ Use `colnames()` to see all variable names\n\n# Explore model assumptions\nplot(turtles_lm)\n\n\n\n\n\n\n\n\n\n\n\n\n# Pearson’s r\nturtles_cor <- cor.test(sea_turtles_clean$length, sea_turtles_clean$width)\nturtles_cor\n\n\n    Pearson's product-moment correlation\n\ndata:  sea_turtles_clean$length and sea_turtles_clean$width\nt = 61.775, df = 280, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9562175 0.9723919\nsample estimates:\n      cor \n0.9652165 \n\n\n\nRegression summary of sea turtle curved carapace length and width at midline (cm).\n\nSimple linear regression was used to explore the relationship between sea turtles curved carapace length at midline (cm) and curved carapace width at widest point (cm) across two sea turtle species: green or loggerhead. A significant regression model was found (\\(\\beta\\) = 1.081, F(1,280) = 3816.1, p < 0.001) with an R2 of 0.932.\n\n\n\nComparing carapace lengths between green and loggerhead turtles\n\n## Lets just look at the raw data \n#ggplot(data = sea_turtles_clean, aes(x = species, y = length)) + geom_boxplot(aes(col=species))\n# not very different.. \n\n# Histograms\nggplot(data = sea_turtles_clean, aes(x = length)) +\n  geom_histogram(bins = 15) +\n  facet_wrap(~species, scales = \"free\")\n\nWarning: Removed 1 rows containing non-finite values (stat_bin).\n\n\n\n\n# QQ Plots\nggplot(data= sea_turtles_clean, aes(sample = length)) +\n  geom_qq() +\n  facet_wrap(~species)\n\nWarning: Removed 1 rows containing non-finite values (stat_qq)."
  },
  {
    "objectID": "posts/2021-03-31-two-sample-t-test/two-sample-t-test.html#two-sample-t-test",
    "href": "posts/2021-03-31-two-sample-t-test/two-sample-t-test.html#two-sample-t-test",
    "title": "Two Sample T-Test",
    "section": "Two sample t-test",
    "text": "Two sample t-test\n\n# two sample t-test\nturtle_length_green <- sea_turtles_clean %>% \n  dplyr::select(c(\"length\", \"species\")) %>% \n  filter(species == \"green\") %>% \n  pull(length)\n\nturtle_length_loggerhead<- sea_turtles_clean %>% \n  dplyr::select(c(\"length\", \"species\")) %>% \n  filter(species == \"loggerhead\") %>% \n  pull(length)\n\nttest <-t.test(turtle_length_green, turtle_length_loggerhead)\nttest_tidy <- tidy(ttest)\n\n#turtles_clean_table <- sea_turtles_clean %>% \n#group_by(species) %>% \n  #summarise(mean_length = mean(length, na.rm=T),\n            #sd_length = sd(length, na.rm=T),\n            #n = n())\n\n# cohens d/ effect size\ncohen_test <- cohen.d(turtle_length_green, turtle_length_loggerhead, na.rm = TRUE)\n\n\nTwo sample t-test conclusions:\n\nI used a two-sample t-test because I wanted to compare differences between 2 groups (turtle species) and compare means (continuous data) of curved carapace lengths.\nThis analysis indicates green sea turtles had a larger mean (92.64 ± 15.78, n = 188; mean ± 1 standard deviation), compares to loggerhead sea turtles which had a smaller mean (89.92 ± 11.44, n = 95; mean ± 1 standard deviation). The actual difference in means from green and loggerhead sea turtles is 2.72. The outcome of the two sample t-test indicated that there is somewhat strong chance of (p > 0.001) of randomly selecting two samples from populations with the same that are this difference by change. In sum, the difference in means is significant (Welch’s two-sample t-test: t(244.17) = 1.65, p-value = 9.98e-02) and the effect size is negligible (Cohen’s d = 0.19).\n\n\n## Finalized table that shows counts and proportions of presence of burrowing barnacles to sea turtle species\"\nsea_turtles_burr <- sea_turtles_clean %>%  \n  dplyr::select(species, burr)\n\nburr_counts <- sea_turtles_burr %>% \n  janitor::tabyl(species, burr)\n\nburr_proportions <- burr_counts %>% \n  adorn_percentages() %>% \n  janitor::adorn_pct_formatting(digits = 2) %>% \n  adorn_ns() %>% \n  drop_na()\n\nburr_ct <- burr_proportions %>% \n  column_to_rownames(var = \"species\")\n\nburr_ct %>%  \n  kable(col.names = c(\"No\",\n                      \"Yes\"),\n    caption = \"**Table 1**: Association between sea turtle species and presence of burrowing barnacles\") %>% \n  kable_styling(full_width = FALSE)\n\n\n\n**Table 1**: Association between sea turtle species and presence of burrowing barnacles\n \n  \n      \n    No \n    Yes \n  \n \n\n  \n    green \n    87.23% (164) \n    12.77% (24) \n  \n  \n    loggerhead \n    69.47%  (66) \n    30.53% (29)"
  },
  {
    "objectID": "posts/2021-03-31-two-sample-t-test/two-sample-t-test.html#chi-square-test-for-independence",
    "href": "posts/2021-03-31-two-sample-t-test/two-sample-t-test.html#chi-square-test-for-independence",
    "title": "Two Sample T-Test",
    "section": "Chi-square test for independence",
    "text": "Chi-square test for independence\n\n## Chi-square test\nburr_ct <- burr_counts %>%   \n  drop_na() %>% \n  column_to_rownames(var = \"species\")\n  \nsurvey_x2 <- chisq.test(burr_ct)\nsurvey_x2\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  burr_ct\nX-squared = 11.938, df = 1, p-value = 0.00055\n\nsurvey_tidy <- tidy(survey_x2)\n\n\nChi-square results and summary\nA chi-square test for independence compares two variables in a contingency table to see if they are related. In a more general sense, it tests to see whether distributions of categorical variables differ from each another. For this analysis, there is a significant association (i.e. non-independence) between sea turtle species and and the presence of burrowing barnacles (\\(\\chi\\)2(1) = 11.94, p-value = 5.5e-04).\n\n\nSea turtle data source:\n\nHeithaus, M. and J. Thomson. 2019. Marine turtles captured during haphazard at-sea surveys in Shark Bay, Australia from February 2008 to December 2013 ver 4. Environmental Data Initiative. https://doi.org/10.6073/pasta/7696e20214fbf84f25d664ff7dc8050c"
  },
  {
    "objectID": "posts/2021-02-23-pca/pca.html",
    "href": "posts/2021-02-23-pca/pca.html",
    "title": "Principal Component Analysis (PCA)",
    "section": "",
    "text": "the world countries data can be found in the data folder of this repo; the Rmd and html files, denoted as a1-task2, can be found in the src folder\nthe qmd format can be found here"
  },
  {
    "objectID": "posts/2021-02-23-pca/pca.html#introduction",
    "href": "posts/2021-02-23-pca/pca.html#introduction",
    "title": "Principal Component Analysis (PCA)",
    "section": "Introduction:",
    "text": "Introduction:\n\nThis scaled PCA analysis explores the relationships and loadings between 18 countries and variables: elevation (> 1200 m above sea level), precipitation of coldest quarter (mm), precipitation of driest quarter (mm), precipitation of warmest quarter (mm), precipitation of wettest quarter (mm), mean temperature of coldest quarter (degC), mean temperature of driest quarter (degC), mean temperature of warmest quarter (degC), and mean temperature of wettest quarter (degC). Dataset is provided by @zander_venter on Kaggle with data obtained by Google Earth Engine. (More information at: https://www.kaggle.com/zanderventer/environmental-variables-for-world-countries/data & https://earthengine.google.com/)\n\n\nLoad packages\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(here)\nlibrary(readxl)\nlibrary(ggfortify) # for PCA\nlibrary(patchwork)\n\n\n\nRead in ‘world_env_vars.csv’\n\nworld_df <- read.csv(here(\"posts\", \"2021-02-23-pca\",\"world_env_vars.csv\")) %>% \n  clean_names()\n\n\n\nwrangling and PCA\n\nworld_pca <- world_df %>% \n  select(elevation, ends_with(\"_quart\")) %>%\n  filter(elevation > 1200) %>% \n  drop_na() %>% \n  scale() %>%\n  prcomp()\n\nworld_pca\n\nStandard deviations (1, .., p=9):\n[1] 2.0291856 1.3855556 1.3181932 0.8171926 0.6272059 0.3402524 0.1792816\n[8] 0.0994290 0.0775711\n\nRotation (n x k) = (9 x 9):\n                          PC1         PC2          PC3         PC4         PC5\nelevation           0.3773162 -0.22399107  0.033034623 -0.61413644  0.35607180\nrain_coldest_quart -0.2434664  0.20650462 -0.582855968 -0.15579242  0.24658534\nrain_driest_quart  -0.1146605 -0.09686381 -0.697043121  0.25292269 -0.09145894\nrain_warmest_quart -0.2150023 -0.63115170 -0.020829345 -0.03516178 -0.30985444\nrain_wettest_quart -0.3162501 -0.51929537  0.004911287 -0.24354957 -0.17884450\ntemp_coldest_quart -0.4630113  0.04754973  0.024175082 -0.24000416  0.36549647\ntemp_driest_quart  -0.3875034  0.31191430  0.025864505 -0.50991035 -0.18110083\ntemp_warmest_quart -0.3797402  0.29085047  0.326382687  0.08113646 -0.31973443\ntemp_wettest_quart -0.3608719 -0.21362489  0.255110707  0.38710314  0.63830509\n                           PC6         PC7         PC8         PC9\nelevation           0.23335774 -0.47943432  0.07981926  0.10832506\nrain_coldest_quart -0.59388842 -0.26780837 -0.22049161  0.01555457\nrain_driest_quart   0.55760952 -0.15357434  0.28596342  0.05457187\nrain_warmest_quart  0.07059181 -0.17814346 -0.60974535 -0.22188708\nrain_wettest_quart -0.34503501  0.15751473  0.57748261  0.24828639\ntemp_coldest_quart  0.33809972  0.41158162 -0.30778561  0.46167376\ntemp_driest_quart   0.19762041  0.05313718  0.16857881 -0.62352171\ntemp_warmest_quart  0.06605625 -0.62760903  0.02635032  0.39612322\ntemp_wettest_quart  0.01230044 -0.22841686  0.18470670 -0.33960278\n\nworld_complete <- world_df %>% \n  drop_na(elevation, ends_with(\"_quart\")) %>% \n  filter(elevation > 1200)\n\n\n\nBiplot output\n\nautoplot(world_pca,\n         data = world_complete,\n         loadings = TRUE,\n         colour = 'country', alpha = 0.5,\n         loadings.label = TRUE,\n         loadings.colour = \"black\",\n         loadings.label.colour = \"black\",\n         loadings.label.vjust = -0.5\n         ) + \n  scale_colour_discrete(name = \"Country\") +\n  theme_minimal() + \n  theme(legend.position=\"none\") +\n  geom_text(aes(label=country), col = \"red\", size = 3)\n\n\n\n#screeplot(world_pca, type = \"lines\")\n\n#world_pca$rotation"
  },
  {
    "objectID": "posts/2021-02-23-pca/pca.html#summary",
    "href": "posts/2021-02-23-pca/pca.html#summary",
    "title": "Principal Component Analysis (PCA)",
    "section": "Summary:",
    "text": "Summary:\n\nThe analysis indicates mean temperature of driest quarter and mean temperature of warmest quarter are strongly positively correlated in multivariate space.\nPrecipitation of warmest quarter is minimally correlated with elevation.\nLastly, elevation is negatively correlated to mean temperature of driest quarter, mean temperature of warmest quarter, and precipitation of coldest quarter.\nPCA analysis also indicates, overall, in multivariate space, countries Rwanda and Burundi are very similar – as well as, countries such as Peru and Bolivia."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Elmera Azadpour",
    "section": "",
    "text": "Howdy! I am a Data Scientist/Data Visualization Specialist with United States Geological Survey (USGS) in the Water Mission Area (WMA). My work involves contributing to individual projects by applying reproducible workflows and data visualization techniques to capture and communicate complex data-intensive concepts to non-technical audiences using a variety of media (such as print, web, research products).\nI obtained a Masters of Environmental Science and Management from the Bren School at UC, Santa Barbara. During my Masters, I worked as an Arnhold Graduate Fellow utilizing remote sensing and projected land use data sets to track changes in land use relating to agricultural abandonment in the U.S. I obtained a Honors Bachelors of Science in Environmental Biology from the University of Utah. My honors thesis examined the effects of inorganic vs organic fertilizer on an urban lawn in Salt Lake City, Utah. During undergrad, I also completed two internships at Lawrence Berkeley National Lab where I conducted research analyzing the effects of rainfall gradients on future gross primary productivity across the Isthmus of Panama.\nBroadly, my interests include climate-ecosystem interactions, urban ecology, terrestrial land surface modeling, ecohydrology, global carbon cycling and geophysical science. I am also passionate about environmental/climate justice, BIPOC representation in STEM, and creating open & reproducible data products."
  },
  {
    "objectID": "Resources.html",
    "href": "Resources.html",
    "title": "Resources",
    "section": "",
    "text": "Links to internship programs:\n\nScience Undergraduate Laboratory Internship (SULI), DOE\nCommunity College Internships (CCI) Program, DOE\nStudent Internships, EPA\nSummer Scholars Internship Program, NSF\nAdditional Internship Programs for NOAA, EPA, NIH, etc\n\n\n\nHelpful NSF GRFP Resources:\n\nWhat is the GRFP, when do I apply?\nGreat website that includes tips, links to additional resources\nAdditional advice for essay writing, examples also included\nTips and essay examples\nBreakdown of GRFP and example essays\n\n\n\nHelpful GRE Resources:\n\nManhattan Prep GRE offers 47 free helpful videos\nKaplan GRE Test Prep 2022\nPrinceton Review GRE Prep 2022\nPrinceton Review Crash Course for the GRE, 6th edition (great for last-minute studying)\nComprehensive Study Guide\nQuizlet Flashcards"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Elmera Azadpour",
    "section": "",
    "text": "code\n\n\nanalysis\n\n\nmusic\n\n\nspotify\n\n\n\n\nexploring spotifyr package: Harry Styles’ discography & my downloaded spotify data\n\n\n\n\n\n\nAug 26, 2022\n\n\nElmera Azadpour\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nlinear model\n\n\n\n\nModel Selection and Justification of Black-throated Blue Warbler capture histories, Hubbard Brook Experimental Forest, 1986 - 2010 .\n\n\n\n\n\n\nSep 18, 2021\n\n\nElmera Azadpour\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nlinear model\n\n\n\n\nSnowshoe hare data exploration and linear regression in Bonanza Creek Experimental Forest: 1999-Present.\n\n\n\n\n\n\nSep 18, 2021\n\n\nElmera Azadpour\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nmodeling\n\n\ndiffusion\n\n\n\n\nModeling dimentional diffusion using parameters such as initial concentration, area of cross section of container, diffusivity, etc.\n\n\n\n\n\n\nMay 4, 2021\n\n\nElmera Azadpour\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nt-test\n\n\n\n\nRegression, two sample t-test, and chi-square analysis of two species of sea turtles in Shark Bay, Australia .\n\n\n\n\n\n\nMar 31, 2021\n\n\nElmera Azadpour\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nraster\n\n\n\n\nRaster of species richness of cetacean species off the coast of California utlizing a probability threshold.\n\n\n\n\n\n\nMar 7, 2021\n\n\nElmera Azadpour\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nhierarchical-clustering\n\n\n\n\nHierarchical clustering by complete linkage to create a dendrogram showing multivariate clustering for water chemistry by site in Santa Barbara, CA.\n\n\n\n\n\n\nMar 7, 2021\n\n\nElmera Azadpour\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\ntext\n\n\nword cloud\n\n\n\n\nCounts and visualizations for the most frequently used words in “The Origin of Species” by Charles Darwin, 6th Edition.\n\n\n\n\n\n\nFeb 23, 2021\n\n\nElmera Azadpour\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nchi-square\n\n\n\n\nThis script analyzes the association between respondents’ political affiliation (coined “conservative” or “liberal” by self-identification) and if they consider themself an environmentalist, followed by a chi-square test for independence.\n\n\n\n\n\n\nFeb 23, 2021\n\n\nElmera Azadpour\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nbinary logistic regression\n\n\n\n\nBinary logistic regression of two dominant Palmetto species of south-central Florida from 1981 - 2017.\n\n\n\n\n\n\nFeb 23, 2021\n\n\nElmera Azadpour\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nPCA\n\n\n\n\nThis PCA analysis explores the relationships and loadings between 18 countries and variables including elevation (> 1200 m above sea level), precipitation of coldest quarter (mm), precipitation of driest quarter (mm), and more.\n\n\n\n\n\n\nFeb 23, 2021\n\n\nElmera Azadpour\n\n\n\n\n\n\nNo matching items"
  }
]